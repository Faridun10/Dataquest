{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from linked_list import LinkedList\n",
    "\n",
    "class Stack(LinkedList):\n",
    "    \n",
    "    def push(self, data):\n",
    "        self.append(data)\n",
    "\n",
    "    def peek(self):\n",
    "        return self.tail.data\n",
    "\n",
    "    \n",
    "    def pop(self):\n",
    "        ret = self.tail.data\n",
    "        if self.length == 1:\n",
    "            self.head = self.tail = None\n",
    "        else:\n",
    "            self.tail = self.tail.prev\n",
    "            self.tail.nex = None\n",
    "        self.length -= 1\n",
    "        return ret\n",
    "    \n",
    "# stack = Stack()\n",
    "# for i in range(1, 4):\n",
    "#     stack.push(i)\n",
    "    \n",
    "# top = stack.pop()\n",
    "# print(stack.peek())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Infix and Postfix Notation\n",
    "\n",
    "Define a function `tokenize()` that, given a string, uses the `str.split()` method to tokenize the expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12', '2', '4', '+', '/', '21', '*']\n"
     ]
    }
   ],
   "source": [
    "def tokenize(expression):\n",
    "    return expression.split()\n",
    "\n",
    "print(tokenize(\"12 2 4 + / 21 *\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Processing an Operator\n",
    "\n",
    "It is very important to perform the operation between the elements that was second to to and the top elements. If we do it the other way around we'll get the wrong result.\n",
    "\n",
    "For example, in the `process_minus()` function we do:\n",
    "\n",
    "`result = second_to_top - top # Correct`\n",
    "\n",
    "and not\n",
    "\n",
    "`result = top - second_to_top # Wrong`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_minus(stack):\n",
    "    top = stack.pop()\n",
    "    second_to_top = stack.pop()\n",
    "    result = second_to_top - top\n",
    "    stack.push(result)\n",
    "    \n",
    "    \n",
    "def process_plus(stack):\n",
    "    top = stack.pop()\n",
    "    second_to_top = stack.pop()\n",
    "    result = second_to_top + top\n",
    "    stack.push(result)\n",
    "    \n",
    "    \n",
    "def process_times(stack):\n",
    "    top = stack.pop()\n",
    "    second_to_top = stack.pop()\n",
    "    result = second_to_top * top\n",
    "    stack.push(result)\n",
    "    \n",
    "    \n",
    "def process_divide(stack):\n",
    "    top = stack.pop()\n",
    "    second_to_top = stack.pop()\n",
    "    result = second_to_top / top\n",
    "    stack.push(result)\n",
    "    \n",
    "    \n",
    "def process_pow(stack):\n",
    "    top = stack.pop()\n",
    "    second_to_top = stack.pop()\n",
    "    result = second_to_top ** top\n",
    "    stack.push(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluating Postfix Expressions\n",
    "\n",
    "Here are the steps we need to follow to implement the `evaluate_postfix()` function.\n",
    "\n",
    "Initialize an empty stack.\n",
    "\n",
    "Tokenize the expression using the `tokenize()` function.\n",
    "\n",
    "For each token, do:\n",
    "    If the token is an operator, call the corresponding function to process it. For example, if we find a `+` we call the `process_plus()` function.\n",
    "    Otherwise (the token is a number) and we push that number to the top of the stack. Since each token is a string, we'll need to convert it to a `float` first.\n",
    "\n",
    "Return the value that is left in the stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_postfix(expression):\n",
    "    tokens = tokenize(expression)\n",
    "    stack = Stack()\n",
    "    for token in tokens:\n",
    "        if token == \"+\":\n",
    "            process_plus(stack)\n",
    "        elif token == \"-\":\n",
    "            process_minus(stack)\n",
    "        elif token == \"*\":\n",
    "            process_times(stack)\n",
    "        elif token == \"/\":\n",
    "            process_divide(stack)\n",
    "        elif token == \"**\":\n",
    "            process_pow(stack)\n",
    "        else:\n",
    "            # The token is not an operator so it must be a number\n",
    "            stack.push(float(token))\n",
    "    return stack.pop()\n",
    "                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the implementation\n",
    "\n",
    "When testing with other expressions we need to add spaces between at two tokens. For example `1 + 3` will work but `1+3` won't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0\n",
      "8.0\n",
      "0.0\n",
      "2.0\n",
      "11.25\n",
      "45.0\n",
      "42.0\n",
      "4.0\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "expressions = [\n",
    "    \"4 6 -\",\n",
    "    \"4 1 2 9 3 / * + 5 - *\",\n",
    "    \"1 2 + 3 -\",\n",
    "    \"1 2 - 3 +\",\n",
    "    \"10 3 5 * 16 4 - / +\",\n",
    "    \"5 3 4 2 - ** *\",\n",
    "    \"12 2 4 + / 21 *\",\n",
    "    \"1 1 + 2 **\",\n",
    "    \"1 1 2 ** +\"\n",
    "]\n",
    "\n",
    "for expression in expressions:\n",
    "    print(evaluate_postfix(expression))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Operator Precedence in Infix Notation\n",
    "\n",
    "The precedence dictionary is used to compare the precedence of two operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "precedence = {\"+\": 1, \"-\": 1, \"*\": 2, \"/\": 2, \"**\": 3}\n",
    "\n",
    "print(precedence[\"/\"] < precedence[\"-\"])\n",
    "print(precedence[\"+\"] < precedence[\"*\"])\n",
    "print(precedence[\"+\"] < precedence[\"-\"])\n",
    "print(precedence[\"/\"] < precedence[\"**\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. From Infix to Postfix\n",
    "\n",
    "On this screen, we'll implement a function `infix_to_postfix()` that, given a string with an expression in infix notation, outputs a string with that expression written in postfix notation.\n",
    "\n",
    "Here's an example of usage:\n",
    "\n",
    "\n",
    "`infix = \"10 + 3 * 5 / ( 16 - 4 )\"`\n",
    "\n",
    "postfix = `infix_to_postfix`(exp)\n",
    "\n",
    "`print(postfix)`\n",
    "\n",
    "\n",
    "10 3 5 * 16 4 - / +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening parenthesis\n",
    "def process_opening_parenthesis(stack):\n",
    "    return stack.push(\"(\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing parenthesis\n",
    "def process_closing_parenthesis(stack, postfix):\n",
    "    # Add tokens until we find the open bracket\n",
    "    while stack.peek() != \"(\":\n",
    "        postfix.append(stack.pop())\n",
    "    # Remove the opening bracket\n",
    "    stack.pop()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Operators\n",
    "def process_operator(stack, postfix, operator):\n",
    "    while len(stack) > 0 and stack.peek() in precedence and precedence[stack.peek()] >= precedence[operator]:\n",
    "        postfix.append(stack.pop())\n",
    "    stack.push(operator)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Operands (any numbers)\n",
    "def process_number(postfix, number):\n",
    "    postfix.append(number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Shunting-yard Algorithm\n",
    "\n",
    "We now have all the pieces we need to implement the infix_to_postfix() function that converts an expression from infix notation to postfix notation.\n",
    "\n",
    "1. We start by splitting the expression into tokens using the `tokenize()` function.\n",
    "\n",
    "2. We initialize an empty stack.\n",
    "\n",
    "3. We initialize and empty postfix token list.\n",
    "\n",
    "4. Iterate over all tokens and for each of them:\n",
    "\n",
    "    * If the token is `\"(\"` we call the `process_opening_parenthesis()` function.\n",
    "    \n",
    "    * If the token is `\")\"` we call the `process_closing_parenthesis()` function.\n",
    "    \n",
    "    * If the token is an `operator` we call the `process_operator()` function.\n",
    "    \n",
    "    * Otherwise, the token is a `number` and we call the `process_number()` function.\n",
    "    \n",
    "\n",
    "5. After processing all tokens, we use a `while` loop to pop the remaining stack element into the postfix token list.\n",
    "\n",
    "6. Use the `str.join()` method to convert the postfix token list into a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infix_to_postfix(expression):\n",
    "    tokens = tokenize(expression)\n",
    "    stack = Stack()\n",
    "    postfix = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token == \"(\":\n",
    "            process_opening_parenthesis(stack)\n",
    "        elif token == \")\":\n",
    "            process_closing_parenthesis(stack, postfix)\n",
    "        elif token in (\"+\", \"-\", \"*\", \"/\", \"**\"):\n",
    "            process_operator(stack, postfix, token)\n",
    "        else:\n",
    "            process_number(postfix, token)\n",
    "    \n",
    "    while len(stack) > 0:\n",
    "        postfix.append(stack.pop())\n",
    "        \n",
    "    return \" \".join(postfix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Evaluating Infix expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(expression):\n",
    "    postfix_expression = infix_to_postfix(expression)\n",
    "    return evaluate_postfix(postfix_expression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "0.0\n",
      "8.0\n",
      "11.25\n",
      "256.0\n",
      "65536.0\n",
      "0.5\n",
      "9.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "expressions = [\n",
    "    \"1 + 1\",\n",
    "    \"1 * ( 2 - ( 1 + 1 ) )\",\n",
    "    \"4 * ( 1 + 2 * ( 9 / 3 ) - 5 )\",\n",
    "    \"10 + 3 * 5 / ( 16 - 4 * 1 )\",\n",
    "    \"2 * 2 * 2 * 2 * 2 * 2 * 2 * 2\",\n",
    "    \"2 ** 2 ** 2 ** 2 ** 2\",\n",
    "    \"( 1 - 2 ) / ( 3 - 5 )\",\n",
    "    \"9 / 8 * 8\",\n",
    "    \"64 / ( 8 * 8 )\",\n",
    "]\n",
    "\n",
    "for expression in expressions:\n",
    "    print(evaluate(expression))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "One of the limitations of our implementation is that it requires spaces to separate every part of the expression. For example, we can evaluate the expression `2 * ( 5 - 3 )`, but we can't evaluate `2 * (5 - 3)` or `2*(5 - 3)`. If you're interested in expanding this, you could think about improving the `tokenize()` method to make it more robust.\n",
    "\n",
    "Another suggestion is to implement other operators â€” for example, the integer division `//`.\n",
    "\n",
    "The `evaluate()` function that we implemented exists in Python as the `eval()` built-in function. The Python implementation can actually evaluate any string of Python code, not only expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
